{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "\n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" style=\"float:right; max-width: 250px; display: inline\" alt=\"IMT\"/> </a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Scénarios d'Apprentissage Statistique](https://github.com/wikistat/Apprentissage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Adaptation Statistique d'un Modèle de Prévision du Pic d'Ozone avec <a href=\"https://cran.r-project.org/\"><img src=\"https://cran.r-project.org/Rlogo.svg\" style=\"max-width: 40px; display: inline\" alt=\"R\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Résumé**: Exploration puis modélisation de données climatiques en utilisant R. L'objectif est de prévoir pour le lendemain un possible dépassement d'un seuil de concentration en ozone à partir d'une prévision déterministe sur un maillage grossier et de variables climatiques locales. Estimation par différentes méthodes: régression [linéaire](http://wikistat.fr/pdf/st-m-app-select.pdf) ou   [logistique](http://wikistat.fr/pdf/st-m-app-rlogit.pdf), [analyse discriminante](http://wikistat.fr/pdf/st-m-app-add.pdf), [arbre de décision](http://wikistat.fr/pdf/st-m-app-cart.pdf), [réseau de neurones](http://wikistat.fr/pdf/st-m-app-rn.pdf), [agrégation de modèle](http://wikistat.fr/pdf/st-m-app-agreg.pdf), [SVM](http://wikistat.fr/pdf/st-m-app-svm.pdf). Comparaison des [erreurs de prévision](http://wikistat.fr/pdf/st-m-app-risque-estim.pdf) sur un échantillon test puis des courbes ROC. Itération sur plusieurs échantillons tests pour analyser la distribution de l'erreur de prévision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif, sur ces données, est d'améliorer la prévision déterministe (MOCAGE), calculée par les services de MétéoFrance,  de la concentration d'ozone dans certaines stations de prélèvement.  Il s'agit d'un problème dit d'*adaptation statistique* d'une prévision locale de modèles à trop grande échelle en s'aidant d'autres variables également gérées par MétéoFrance, mais à plus petite échelle (température, force du vent...). Plus précisément, deux variables peuvent être prévues : soit la concentration quantitative d'ozone, soit le dépassement (qualitatif) d'un certain seuil fixé à 150 $\\mu g$. Dans chaque cas, deux approches sont considérées : soit prévoir la *concentration quantitative* puis en déduire l'éventuel dépassement ou bien prévoir directement le *dépassement*. Dans le premier cas, il s'agit d'abord d'une *régression* tandis que dans le deuxième il s'agit d'un problème de *discrimination* à deux classes ou de régression logistique. \n",
    "\n",
    "La question posée est donc: quelles sont les meilleures méthodes et stratégies pour prévoir la concentration d'ozone du lendemain d'une part et l'occurrence d'un pic de pollution d'autre part.\n",
    "\n",
    "On se propose de tester différentes méthodes : régression [logistique](http://wikistat.fr/pdf/st-m-app-rlogit.pdf), [analyse discriminante](http://wikistat.fr/pdf/st-m-app-add.pdf), [réseau de neurones](http://wikistat.fr/pdf/st-m-app-rn.pdf), [arbre de décision](http://wikistat.fr/pdf/st-m-app-cart.pdf), [agrégation d'arbres](http://wikistat.fr/pdf/st-m-app-agreg.pdf) (bagging, boosting, random forest), [SVM](http://wikistat.fr/pdf/st-m-app-svm.pdf).  L'objectif final, à ne pas perdre de vue, est la comparaison de ces méthodes afin de déterminer la plus efficace pour répondre au problème de prévision. Ceci passe par la mise en place d'un protocole très strict afin de s'assurer d'un minimum d'objectivité pour cette comparaison.\n",
    "\n",
    "Toutes les opérations sont réalisées dans R avec l'appui de bibliothèques complémentaires éventuellement à télécharger (ROCR, mlbench, MASS, boot, class, e1071, rpart, partykit, nnet, ipred, gbm, randomForest). \n",
    "\n",
    "Python (consulter le [calepin](http://www.math.univ-toulouse.fr/~besse/Wikistat/Notebooks/Notebook-Python-Ozone.html)) conduit à des résultats identiques mais moins complets pour leur interprétation. En particulier, l'absence du type *DataFrame* dans la librairie scikit-learn n'autorise pas une sélection fine des variables dans les modèles statistiques usuels. En revanche, l'exécution est beaucoup plus rapide en python pour itérer les exécutions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Prise en charge des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données ont été extraites et mises en forme par le service concerné de Météo France. Elles sont décrites par les variables suivantes:\n",
    "\n",
    "\n",
    "* **JOUR** Le type de jour ; férié (1) ou pas (0) ;\n",
    "* **O3obs** La concentration d'ozone effectivement observée le lendemain à 17h locales correspondant souvent au maximum de pollution observée ;\n",
    "* **MOCAGE** Prévision de cette pollution obtenue par un modèle déterministe de mécanique des fluides (équation de Navier et Stockes);\n",
    "* **TEMPE** Température prévue par MétéoFrance pour le lendemain 17h ;\n",
    "* **RMH2O** Rapport d'humidité ;\n",
    "* **NO2** Concentration en dioxyde d'azote ;\n",
    "* **NO** Concentration en monoxyde d'azote ;\n",
    "* **STATION** Lieu de l'observation : Aix-en-Provence, Rambouillet, Munchhausen, Cadarache et Plan de Cuques ;\n",
    "* **VentMOD** Force du vent ;\n",
    "* **VentANG** Orientation du vent. \n",
    "\n",
    "Ce sont des données \"propres\", sans trous, bien codées et de petites tailles. Elles présentent donc avant tout un caractère pédagogique car permettant de décliner puis comparer toutes les approches de régression et classification supervisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      JOUR            O3obs           MOCAGE          TEMPE      \n",
       " Min.   :0.0000   Min.   : 19.0   Min.   : 46.4   Min.   :10.40  \n",
       " 1st Qu.:0.0000   1st Qu.: 87.0   1st Qu.: 97.5   1st Qu.:20.20  \n",
       " Median :0.0000   Median :109.0   Median :125.6   Median :23.80  \n",
       " Mean   :0.3045   Mean   :115.4   Mean   :127.2   Mean   :23.88  \n",
       " 3rd Qu.:1.0000   3rd Qu.:135.0   3rd Qu.:153.6   3rd Qu.:27.60  \n",
       " Max.   :1.0000   Max.   :319.0   Max.   :284.7   Max.   :38.00  \n",
       "     RMH2O              NO2               NO         STATION  \n",
       " Min.   :0.00285   Min.   : 0.258   Min.   :0.0010   Aix:199  \n",
       " 1st Qu.:0.00763   1st Qu.: 1.248   1st Qu.:0.2360   Als:222  \n",
       " Median :0.00985   Median : 2.109   Median :0.3880   Cad:202  \n",
       " Mean   :0.01025   Mean   : 3.505   Mean   :0.6574   Pla:208  \n",
       " 3rd Qu.:0.01244   3rd Qu.: 4.062   3rd Qu.:0.7440   Ram:210  \n",
       " Max.   :0.02753   Max.   :44.396   Max.   :9.4290            \n",
       "    VentMOD           VentANG       \n",
       " Min.   : 0.1414   Min.   :-1.5708  \n",
       " 1st Qu.: 3.9623   1st Qu.:-0.3948  \n",
       " Median : 5.5973   Median : 0.2783  \n",
       " Mean   : 5.9072   Mean   : 0.1631  \n",
       " 3rd Qu.: 7.1063   3rd Qu.: 0.6926  \n",
       " Max.   :19.8910   Max.   : 1.5708  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lecture des données\n",
    "path=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/data/\"\n",
    "ozone=read.table(paste(path,\"depSeuil.dat\",sep=\"\"),sep=\",\",header=T)\n",
    "# Vérification du contenu\n",
    "summary(ozone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Changement du type de la variable jour en facteur\n",
    "ozone[,\"JOUR\"]=as.factor(ozone[,\"JOUR\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploration élémentaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarquer le type des variables. Il est nécessaire d'en étudier la distribution. Noter la symétrie ou non de celles-ci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist(ozone[,\"O3obs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist(ozone[,\"NO2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Même chose pour les autres variables\n",
    "# hist(ozone[,\"MOCAGE\"]);hist(ozone[,\"TEMPE\"]);hist(ozone[,\"RMH2O\"])\n",
    "# hist(ozone[,\"NO\"]);hist(ozone[,\"VentMOD\"]);hist(ozone[,\"VentANG\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Des transformations sont proposées pour rendre certaines distributions plus symétriques et ainsi plus \"gaussiennes\". C'est nécessaire pour certaines méthodes à venir de modélisation (linéaires), par pour toutes (arbres)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ozone[,\"SRMH2O\"]=sqrt(ozone[,\"RMH2O\"])\n",
    "ozone[,\"LNO2\"]=log(ozone[,\"NO2\"])\n",
    "ozone[,\"LNO\"]=log(ozone[,\"NO\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifier l'opportunité de ces transformations puis retirer les variables initiales et construire la variable \"dépassement de seuil\" pour obtenir le fichier qui sera effectivement utilisé.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ozone=ozone[,c(1:4,8:13)]\n",
    "ozone[,\"DepSeuil\"]=as.factor(ozone[,\"O3obs\"]>150)\n",
    "summary(ozone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pairs(ozone[,c(3,4,6:10)])\n",
    "# Noter la natue des relations ou de l'ansence de relation entre les variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les commandes suivantes permettent de réaliser une analyse en composantes principales sur les seules variables quantitatives. Par ailleurs la variable à modéliser  (O3obs, concentration observée) n'est pas utilisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ACP réduite\n",
    "acp=princomp(ozone[,c(3:4,6:10)],cor=TRUE)\n",
    "# Décroissance des valeurs propres\n",
    "par(mfrow = c(2,1))\n",
    "plot(acp); boxplot(data.frame(acp$scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que sont ces graphiques ? Que dire du choix de la dimension, des valeurs atypiques?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "biplot(acp, col=c(\"grey\",\"blue\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que dire de la structure de corrélation ds variables ? Est-elle intuitive ?\n",
    "\n",
    "Le même graphique en coloriant les jours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coul=as.integer(ozone[,\"DepSeuil\"])\n",
    "plot(acp$scores,col=coul, pch=17+coul)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif est donc de définir une surface séparant les deux classes. Une discriminaiton linéaire (hyperplan) semble-t-elle possible? \n",
    "\n",
    "Ce n'est pas utile ici mais une classification non supervisée est facile à obtenir. Par exemple en 4 classes, par l'algorithme k-means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "km.ozone=kmeans(ozone[,c(3:4,6:10)],centers=4)\n",
    "# Représentatino dans les coordonnées de l'acp\n",
    "coul=km.ozone$cluster\n",
    "plot(acp$scores,col=coul, pch=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Protocole de comparaison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Stratégie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La recherche  d'une meilleure méthode de prévision suit le protocole suivant.\n",
    "\n",
    "1. Etape descriptive préliminaire uni et multidimensionnelle visant à repérer les incohérences, les variables non significatives ou de distribution exotique, les individus non concernés ou atypiques... et à étudier les structures des données. Ce peut être aussi la longue étape de construction de variables, attributs ou *features* spécifiques des données. \n",
    "2. Procéder à un tirage aléatoire d'un échantillon *test* qui ne sera utilisé que lors de la *dernière étape* de comparaison des méthodes.\n",
    "3. La partie restante est l'échantillon d'*apprentissage* pour l'estimation des paramètres des modèles.\n",
    "4. Pour chacune des méthodes, optimiser la complexité des modèles en minimisant une estimation \"sans biais\" de l'erreur de prévision, par exemple par *validation croisée*.\n",
    "    - Variables et interactions à prendre en compte dans la régression linéaire ou logistique;\n",
    "    - variables et méthode pour l'analyse discriminante;\n",
    "    - nombre de feuilles dans l'arbre de régression ou de classification;\n",
    "    - architecture (nombre de neurones, pénalisation) du perceptron;\n",
    "    - algorithme d'agrégation, \n",
    "    - noyau et pénalisation des SVMs.\n",
    "5.  Comparaison des qualités de prévision sur la base du taux de mal classés pour le seul échantillon test qui est resté à l'écart de tout effort ou \"acharnement\" pour l'optimisation des modèles.\n",
    "\n",
    "**Remarques**\n",
    "* En cas d'échantillon relativement \"petit\" il est recommandé d'itérer la procédure de découpage apprentissage / test, afin de réduire la variance (moyenne) des estimations des erreurs de prévision.\n",
    "* *Attention*: ne pas \"tricher\" en modifiant le modèle obtenu lors de l'étape précédente afin d'améliorer le résultat sur l'échantillon test !\n",
    "* Le critère utilisé dépend du problème : erreur quadratique, taux de mauvais classement, AUC (aire sous la courbe ROC), indice de Pierce, *log loss function*..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Extraction des échantillons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les commandes ci-dessous réalisent l'extraction du sous-ensemble des données d'apprentissage et de test. Attention, chaque participant tire un échantillon différent ; il est donc \"normal\" de na pas obtenir les mêmes modèles, les mêmes résultats.\n",
    "\n",
    "Utiliser trois chiffres au hasard, en remplacement de \"XXX\" ci-dessous, comme initialisation du générateur de nombres aléatoires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set.seed(XXX) # initialisation du générateur\n",
    "# Extraction des échantillons\n",
    "test.ratio=.2   # part de l'échantillon test\n",
    "npop=nrow(ozone) # nombre de lignes dans les données\n",
    "nvar=ncol(ozone) # nombre de colonnes\n",
    "# taille de l'échantillon test\n",
    "ntest=ceiling(npop*test.ratio) \n",
    "# indices de l'échantillon test\n",
    "testi=sample(1:npop,ntest)\n",
    "# indices de l'échantillon d'apprentissage\n",
    "appri=setdiff(1:npop,testi) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construction des échantillons pour la régression: prévision de la concentration en ozone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# construction de l'échantillon d'apprentissage\n",
    "datappr=ozone[appri,-11] \n",
    "# construction de l'échantillon test\n",
    "datestr=ozone[testi,-11] \n",
    "summary(datappr) # vérification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construction des échantillons pour la discrimination: prévision de dépassement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# construction de l'échantillon d'apprentissage\n",
    "datappq=ozone[appri,-2]\n",
    "# construction de l'échantillon test \n",
    "datestq=ozone[testi,-2] \n",
    "summary(datappq) # vérification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prévision par modèle gaussien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le premier modèle à tester est un simple modèle de régression linéaire mais, comme certaines variables sont qualitatives, il s'agit d'une analyse de covariance. D'autre part, on s'intéresse à savoir si des interactions sont à prendre en compte. Le modèle devient alors polynomiale d'ordre 2 ou quadratique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Modèle linéaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle de régression linéaire simple intégre des variables qualitatives; c'est dans ce cas une *analyse de covariance*  estimée par la fonction aov mieux adaptée à ce modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# estimation du modèle sans interaction\n",
    "reg.lm=aov(O3obs~.,data=datappr)\n",
    "# Extraction des résidus et des valeurs ajustées\n",
    "# de ce modèle\n",
    "res.lm=reg.lm$residuals\n",
    "fit.lm=reg.lm$fitted.values\n",
    "# graphe des résidus\n",
    "# Définition d'une fonction pour un graphe coloré et \n",
    "# des échelles fixes sur les axes\n",
    "plot.res=function(x,y,titre=\"titre\")\n",
    "{\n",
    "plot(x,y,col=\"blue\",xlim=c(0,300),ylim=c(-100,100),\n",
    "ylab=\"Résidus\",xlab=\"Valeurs predites\",main=titre)\n",
    "# points(x2,y,col=\"red\")\n",
    "abline(h=0,col=\"green\")\n",
    "}\n",
    "plot.res(fit.lm,res.lm,\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que dire de la distribution de ces résidus ? La forme du nuage renseigne sur les hypothèses de linéarité du modèle et d'homoscédasticité. Que dire de la validité de ce modèle ?\n",
    "\n",
    "Apprécier néanmoins sa significativité par la commande suivante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary(reg.lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce premier modèle est comparé avec celui de la seule prévision déterministe. Qu'en conclure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Graphe des résidus du modèle déterministe MOCAGE\n",
    "plot.res(datappr[,\"MOCAGE\"],datappr[,\"MOCAGE\"]-datappr[,\"O3obs\"],\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Modèle quadratique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'étude suivante met en oeuvre toutes les interactions d'ordre 2 entre les variables. Il s'agit donc d'un modèle de régression quadratique. Il est estimé avec la fonction glm qui permet une sélection automatique de modèle. La méthode descendante est utilisée mais celle pas-à-pas pourrait également l'être. Ce type de procédure n'est pas implémentée en python.\n",
    "\n",
    "Sélection descendante: à chaque étape, chaque modèle est comparé à tous les sous-modèles possibles obtenus par suppression d'une des interactions ou une des variables, à condition qu'elle ne soit pas présente dans une interaction. La variable sélectionnée et supprimée est celle qui fait décroîre le critère considéré : AIC ou *Akaïke Information Criterion*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Estimation du modèle de toute interaction d'ordre 2\n",
    "reg.glm=glm(O3obs~(.)^2,data=datappr)\n",
    "# Recherche du meilleur modèle au sens \n",
    "# du critère d'Akaïke par méthode descendante\n",
    "reg.glm.step=step(reg.glm,direction=\"backward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Coefficients du modèle\n",
    "anova(reg.glm.step,test=\"F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extraction des valeurs ajustées et des résidus\n",
    "fit.glm=reg.glm.step$fitted.values\n",
    "res.glm=reg.glm.step$residuals\n",
    "# Graphe des résidus\n",
    "plot.res(fit.glm,res.glm,\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " On remarque que la présence de certains interactions ou variables sont pertinentes au sens du critère d'Akaïke mais pas significative au sens du test de Fisher. Cette présence dans le modèle pourrait être plus finement analysée en considérant une estimation de l'erreur par validation croisée. L'idée serait de retirer une à une les variables ou interactions les moins significatives pour voir comment se comporte la validation croisée. D'autre part, si la procédure pas-à-pas conduit à un modèle différent, l'estimation de l'erreur par validation croisée permet également d'optimiser le choix.\n",
    " \n",
    "Ces raffinements ne s'avèrent pas efficace sur ces données. Le modèle obtenu par minimisaiton du critère AIC est conservé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Prévision de l'échantillon test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle \"optimal\"  obtenu pest utilisé pour prédire l'échantillon test et estimer ainsi, sans biais, une erreur de prévision. Deux erreurs sont estimées ; la première est celle quadratique pour la régression tandis que la deuxième est issue de la matrice de confusion qui croise les dépassements de seuils prédits avec ceux effectivement observés. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calcul des prévisions\n",
    "pred.glm=predict(reg.glm.step,newdata=datestr)\n",
    "# Erreur quadratique moyenne de prévision (MSE)\n",
    "sum((pred.glm-datestr[,\"O3obs\"])^2)/nrow(datestr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Erreur quadratique par MOCAGE\n",
    "sum((datestr[,\"MOCAGE\"]-datestr[,\"O3obs\"])^2)/nrow(datestr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Matrice de confusion pour la prévision du \n",
    "# dépassement de seuil\n",
    "table(pred.glm>150,datestr[,\"O3obs\"]>150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Matrice de confusion pour la prévision du \n",
    "# dépassement de seuil par MOCAGE\n",
    "table(datestr[,\"MOCAGE\"]>150,datestr[,\"O3obs\"]>150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noter ces erreurs pour les comparer avec celles obtenues par les autres méthodes. Noter l'asymétrie des erreurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prévision par modèle binomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plutôt que de prévoir la concentration puis le dépassement, on peut se poser la question de savoir s'il ne serait pas pertinent de prévoir directement la présence ou l'absence d'un dépassement. La variable à modéliser étant binaire, c'est la régression logistique qui va être employée. Comme pour la régression, différentes stratégies de choix de modèle peuvent être utilisées et comparées avant d'estimer l'erreur de prévision sur l'échantillon test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Régression logistique sans interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# estimation du modèle complet\n",
    "log.lm=glm(DepSeuil~.,data=datappq,family=binomial)\n",
    "# significativité des paramètres\n",
    "anova(log.lm,test=\"Chisq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Recherche d'un modèle optimal au sens d'Akaïke\n",
    "log.lm.step=step(log.lm,direction=\"backward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Modèle obtenu\n",
    "anova(log.lm.step,test=\"Chisq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# matrice de confusion de l'échantillon \n",
    "# d'apprentissage et erreur apparente\n",
    "table(log.lm.step$fitted.values>0.5,\n",
    "   datappq[,\"DepSeuil\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Régression logistique avec interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec autant de variables et d'interactions donc de paramètres, l'estimation du modèle complet de régression logistique  rencontre des soucis et affiche des *warnings* car certaines probabilité trop bien ajustés (0 ou 1) provoquent des divisions par 0. Ici une procédure *forward* ou  mieux *stepwise* de sélection des variables et interactions  conduit à des résultats raisonnables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# régression avec le modèle minimum\n",
    "log.qm=glm(DepSeuil~1,data=datappq,family=binomial)\n",
    "# algorithme stepwise en précisant le plus grand \n",
    "# modèle possible\n",
    "log.qm.step1=step(log.qm,direction=\"both\",\n",
    "  scope=list(lower=~1,upper=~(JOUR + MOCAGE + \n",
    "  TEMPE + STATION + VentMOD + VentANG + LNO2 + \n",
    "  LNO + SRMH2O)^2), family=binomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "anova(log.qm.step1,test=\"Chisq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prévision\n",
    "pred.log=predict(log.qm.step1,newdata=datestq,type=\"response\")\n",
    "# Matrice de confusion pour la prévision du \n",
    "# dépassement de seuil\n",
    "table(pred.log>0.5,datestq[,\"DepSeuil\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparer avec l'approche précédente. Mémoriser les résultats obtenus pour comparer avec les autres méthodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Courbe ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est également possible de construire une courbe ROC en association de la prévision obtenue à partir d'un modèle gaussien. En effet, la variation du seuil théorique de dépassement (150) va faire varier les proportions respectives des taux de vrais et faux positifs. Cela revient encore à faire varier le seuil d'une \"proba\" pour les valeurs de prévisions divisées par 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(ROCR)   # Librairie à charger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roclogit=predict(log.qm.step1,newdata=datestq,type=\"response\")\n",
    "predlogit=prediction(roclogit,datestq[,\"DepSeuil\"])\n",
    "perflogit=performance(predlogit, \"tpr\",\"fpr\")\n",
    "# Tracé de la courbe\n",
    "plot(perflogit,col=1)\n",
    "# Calculs pour la régression\n",
    "rocglm=pred.glm/300\n",
    "predglm=prediction(rocglm,datestq[,\"DepSeuil\"])\n",
    "perfglm=performance(predglm, \"tpr\",\"fpr\")\n",
    "# tracé de la courbe et ajout au graphe précédent.\n",
    "plot(perfglm,col=2,add=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Les résultats obtenus dépendent évidemment en plus de l'échantillonnage initial entre apprentissage et test. Dans le cas où les courbes se croisent, cela signifie qu'il n'y a pas de prévision uniformément meilleure de l'occurrence de dépassement. Cela dépend de la sensibilité ou de la spécificité retenue pour le modèle. Ceci souligne l'importance de la bonne définition du critère à utiliser pour le choix d'une \"meilleure\" méthode. Ce choix dépend directement de celui , \"politique\" ou \"économique\" de sensibilité et / ou spécificité du modèle retenu. En d'autres termes, quel taux de fausse alerte, avec des imputations économiques évidentes, est supportable au regard des dépassements non détectés et donc de la dégradation sanitaire de la population à risque ?\n",
    " \n",
    "C'est une fois ce choix arrêté que le statisticien peut opérer une comparaison des méthodes en présence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analyse discriminante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " L'objectif est de comparer les trois méthodes d'analyses discriminantes disponibles dans R : lda paramétrique linéaire (homoscédasticité), lqa paramétrique quadratique (hétéroscédasticité) sous hypothèse gaussienne et celle non-paramétrique des $k$ plus proches voisins.\n",
    " \n",
    "*Attention*, ces techniques n'acceptent par principe que des variables explicatives ou prédictives quantitatives. Néanmoins, une variable qualitative à deux modalités, par exemple le type de jour, peut être considérée comme quantitative sous la forme d'une fonction indicatrice prenant ses valeurs dans $\\{0, 1\\}$ et, de façon plus \"abusive\", une variable ordinale est considérée comme \"réelle\". Dans ce dernier cas, il ne faut pas tenter d'interpréter les fonctions de discrimination, juste considérer des erreurs de prévision. La variable *Station* n'est pas prise en compte.\n",
    "\n",
    "La bibliothèque standard de R (MASS) pour l'analyse discriminante ne propose pas de procédure automatique de choix de variable mais, dans cet exemple, les variables sont peu nombreuses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Estimation des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(MASS) # chargement des librairies\n",
    "library(class) # pour kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# analyse discriminante linéaire\n",
    "disc.lda=lda(DepSeuil~.,data=datappq[,-4]) \n",
    "# analyse discriminante quadratique \n",
    "disc.qda=qda(DepSeuil~.,data=datappq[,-4]) \n",
    "# k plus proches voisins\n",
    "disc.knn=knn(datappq[,c(-4,-10)],datappq[,c(-4,-10)],datappq$DepSeuil,k=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noter le manque d'homogénéité des commandes de R issues de librairies différentes. L'indice de colonne négatif ($-10$) permet de retirer la colonne contenant la variable à prédire de type facteur. Celle-ci est mentionnée en troisième paramètre pour les données d'apprentissage. La librairie [caret](http://topepo.github.io/caret/index.html) contourne ces difficultés en englobant toutes les librairies d'apprentissage et en homogénéisant les appels pour l'estimation et la prévision des modèles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Estimation de l'erreur de prévision par validation croisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# erreur par validation croisée  en analyse discriminante linéaire\n",
    "disc.lda=lda(DepSeuil~.,data=datappq[,-4],CV=T) \n",
    "# estimer le taux d'erreur à partir de la matrice de confusion\n",
    "table(datappq[,\"DepSeuil\"],disc.lda$class) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# analyse discriminante quadratique\n",
    "disc.qda=qda(DepSeuil~.,data=datappq[,-4],CV=T)  \n",
    "table(datappq[,\"DepSeuil\"],disc.qda$class) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour knn, le choix du nombre de voisins $k$ peut être optimisé par validation croisée mais la procédure proposée par la bibliothèque class est celle *leave-one-out*, donc trop coûteuse en calcul pour des gros fichiers. Il serait simple de la programmer mais une autre bibliothèque (e1071) propose déjà une batterie de fonctions de validation croisée pour de nombreuses techniques de discrimination. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# k plus proches voisins: optimisaiton de k\n",
    "library(e1071)\n",
    "plot(tune.knn(as.matrix(datappq[,c(-4,-10)]),as.factor(datappq[,10]),k=2:20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lancer plusieurs exécutions successives de cette \"optimisation\". Que remarque-t-on ? Comment choisir k ? Comparer avec les erreurs précédentes estimées également par validation croisée. Quelle analyse discriminante retenir ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Erreur sur l'échantillon test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les commandes suivantes calculent la matrice de confusion pour la \"meilleure\" méthode d'analyse discriminante au sens de la validation croisée. Cette \"meilleure\" méthode peut être edifférente d'un participant à l'autre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "disc.lda=lda(DepSeuil~.,data=datappq[,-4])  \n",
    "table(datestq[,\"DepSeuil\"],predict(disc.lda,datestq[,-4])$class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A titre indicatif, voici l'estimation de l'erreur sur l'échantillon test pour la méthode des $k$ plus proches voisins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "disc.knn=knn(as.matrix(datappq[,c(-4,-10)]),as.matrix(datestq[,c(-4,-10)]),datappq$DepSeuil,k=15)\n",
    "table(disc.knn,datestq$DepSeuil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Courbes ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ROCdiscrim=predict(disc.lda,datestq[,c(-4)])$posterior[,2]\n",
    "preddiscrim=prediction(ROCdiscrim,datestq$DepSeuil)\n",
    "perfdiscrim=performance(preddiscrim,\"tpr\",\"fpr\")\n",
    "# tracer les courbes ROC en les superposant pour mieux comparer\n",
    "plot(perflogit,col=1) \n",
    "plot(perfdiscrim,col=2,add=TRUE)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une méthode est elle uniformément meilleure sur cet échantillon test ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Arbre de décision binaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librairie rpart est celle la plus couramment utilisée pour la construction d'arbres de décision. Deux types d'arbre peuvent être estimer selon que la variable à modéliser est la concentration d'ozone (arbre de régression) ou directement le dépassement du seuil (arbre de discrimination ou de décision). Différents paramètres  contrôlent l'exécution de l'algorithme: la pénalisation  minimale (cp) pour la construction de l'arbre maximal, le nombre minimal d'observation par noeud, le nombre de validations croisées (par défaut 10)... cf. l'aide en ligne (?rpart.control) pour plus de détails mais celle-ci n'est pas très explicite sur certains paramètres, c'est le travers des logiciels \"libres\".\n",
    "\n",
    "**NB.** Une séquence de valeurs de la pénalisation cp est associée à une séquence d'arbres emboîtés.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Estimation et élagage de l'arbre de régression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(rpart) # chargement de la librairie\n",
    "tree.reg=rpart(O3obs~.,data=datappr,control=rpart.control(cp=0.001))\n",
    "# La commande ci-dessous fournit un descriptif de l'arbre obtenu\n",
    "# summary(tree.reg)  \n",
    "# mais un graphe est  préférable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(tree.reg)\n",
    "text(tree.reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'arbre est illisible et présente trop de feuilles pour une bonne prévision (sur-apprentissage), il est nécessaire d'en réduire le nombre par élagage. Les commandes suivantes calculent les prévisions obtenues par  validation croisée *10-fold* pour chaque arbre élagué suivant les valeurs successives du coefficient de complexité. La séquence de ces valeurs est implicitement celle fournit par rpart. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xmat=xpred.rpart(tree.reg)\n",
    "xerr=(xmat-datappr[,\"O3obs\"])^2\n",
    "CVerr=apply(xerr,2,sum)\n",
    "CVerr  #    CP           erreur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chercher la valeur de cp correspondant à la plus petite erreur puis l'utiliser la construction del'arbre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "as.numeric(attributes(which.min(CVerr))$names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree.reg=rpart(O3obs~.,data=datappr,control=rpart.control(cp=as.numeric(attributes(which.min(CVerr))$names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librairie partykit propose une construction graphique de l'arbre:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(partykit)\n",
    "plot(as.party(tree.reg), type=\"simple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fenêtre est trop petite pour représenter les distributions (histogramme) de la variable cible (concentration en ozone) dans chaque feuille. Remarquer les variables les plus explicatives en haut de l'arbre.\n",
    "\n",
    "Graphe des résidus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fit.tree=predict(tree.reg)\n",
    "res.tree=fit.tree-datappr[,\"O3obs\"]\n",
    "plot.res(fit.tree,res.tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expliquer la structure particulière de ce graphe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Estimation et élagage d'un arbre de discrimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le cas d'une discrimination, le critère par défaut est l'indice de concentration de Gini ; il est possible de préciser le critère d'entropie (split=\"information\") ainsi que des poids sur les observations, une matrice de coûts de mauvais classement ainsi que des probabilités *a priori* (?rpart pour plus de détails)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree.dis=rpart(DepSeuil~.,data=datappq,parms=list(split=\"information\"),cp=0.001)\n",
    "plot(tree.dis) \n",
    "text(tree.dis)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Elagage par validation croisée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La même procédure est mise en place mais avec un expression différente de l'erreur de prévision: taux de mal classés plutôt qu'erreur quadratique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xmat = xpred.rpart(tree.dis)\n",
    "# Comparaison des valeurs prédite et observée\n",
    "xerr=datappq$DepSeuil!= (xmat>1.5) \n",
    "# Calcul  des estimations des taux d'erreur\n",
    "CVerr=apply(xerr, 2, sum)/nrow(xerr)\n",
    "CVerr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "as.numeric(attributes(which.min(CVerr))$names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree.dis=rpart(DepSeuil~.,data=datappq,parms=list(split=\"information\"),\n",
    "               cp=as.numeric(attributes(which.min(CVerr))$names))\n",
    "plot(as.party(tree.dis), type=\"simple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Prévision de l'échantillon test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Différentes prévisions sont considérées assorties des erreurs estimées sur l'échantillon test. Prévision quantitative de la concentration, prévision de dépassement à partir de la prévision quantitative et directement la prévision de dépassement à partir de l'arbre de décision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calcul des prévisions\n",
    "pred.treer=predict(tree.reg,newdata=datestr)\n",
    "pred.treeq=predict(tree.dis,newdata=datestq,type=\"class\") \n",
    "# Erreur quadratique moyenne de prévision en régression\n",
    "sum((pred.treer-datestr[,\"O3obs\"])^2)/nrow(datestr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Matrice de confusion pour la prévision du \n",
    "# dépassement de seuil (régression)\n",
    "table(pred.treer>150,datestr[,\"O3obs\"]>150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Même chose pour l'arbre de discrimination\n",
    "table(pred.treeq,datestq[,\"DepSeuil\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Courbes ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ROCregtree=pred.treer/300\n",
    "predregtree=prediction(ROCregtree,datestq$DepSeuil)\n",
    "perfregtree=performance(predregtree,\"tpr\",\"fpr\")\n",
    "ROCdistree=predict(tree.dis,newdata=datestq,type=\"prob\")[,2]\n",
    "preddistree=prediction(ROCdistree,datestq$DepSeuil)\n",
    "perfdistree=performance(preddistree,\"tpr\",\"fpr\")\n",
    "# tracer les courbes ROC en les superposant \n",
    "# pour mieux comparer\n",
    "plot(perflogit,col=1)\n",
    "plot(perfregtree,col=2,add=TRUE) \n",
    "plot(perfdistree,col=3,add=TRUE)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparer les qualités  de prévision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 Réseau de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il s'agit d'estimer un modèle de type *perceptron* avec en entrée les variables qualitatives ou quantitatives et en sortie la variable à prévoir. Des fonctions R pour l'apprentissage d'un perceptron élémentaire ont été réalisées par différents auteurs et sont accessibles sur le réseau. La librairie nnet de (Ripley, 1999), est limitée au perceptron à une couche. Ce n'est pas de l'*apprentissage profond* ! mais suffisant dans bien des cas. Une librairie R associée au logiciel éponyme H2O propose des réseaux à plusieurs couches et \"convolutionnels\".\n",
    "\n",
    "Comme pour les arbres, la variable à expliquer est soit quantitative soit qualitative ; la fonction de transfert du neurone de sortie d'un réseau doit être adaptée en conséquence. Elle est choisie linéaire dans le cas quantitatif et sigmoïdale (choix par défaut) comme toutes celles de la couche cachée dans le cas qualitatif. Le paramètre important à déterminer est le nombre de neurones sur la couche cachée parallèlement aux conditions d'apprentissage (temps ou nombre de boucles). Une alternative ou un complément à la détermination du nombre de neurones est celle du *decay* qui est un paramètre de régularisation analogue à celui utilisé en régression *ridge*. Il pénalise la norme du vecteurs des paramètres et contraint ainsi la flexibilité du modèle. Très approximativement il est d'usage de considérer, qu'en moyenne, il faut une taille d'échantillon d'apprentissage 10 fois supérieure au nombre de poids c'est-à-dire au nombre de paramètres à estimer. On remarque qu'ici la taille de l'échantillon d'apprentissage (832) est modeste pour une application raisonnable du perceptron. Seuls des nombres restreints de neurones peuvent être considérés et sur une seule couche cachée. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Cas de la régression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(MASS)\n",
    "library(nnet)\n",
    "# apprentissage\n",
    "# attention au paramètre linout dans le cas de la régression\n",
    "nnet.reg=nnet(O3obs~.,data=datappr,size=5,decay=1,linout=TRUE,maxit=500) \n",
    "summary(nnet.reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La commande donne la \"trace\" de l'exécution avec le comportement de la convergence mais le détail des poids de chaque entrée de chaque neurone ne constituent pas des résultats très explicites ! Contrôler le nombre de poids estimés.\n",
    "\n",
    "L'optimisation des paramètres nécessite encore le passage par la validation croisée. Il n'y a pas de fonction dans la librairie nnet permettant de le faire mais la fonction tune.nnet de la librairie e1071 est adaptée à cette démarche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(e1071)\n",
    "plot(tune.nnet(O3obs~.,data=datappr,size=c(2,3,4),decay=c(1,2,3),maxit=200,linout=TRUE))\n",
    "plot(tune.nnet(O3obs~.,data=datappr,size=4:5,decay=1:10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faire éventuellement varier la grille des paramètres (zoom), noter la taille et le *decay* optimaux. Il faudrait aussi  faire varier le nombre total d'itérations. Cela risque de prendre un peu de temps ! Noter également que chaque exécution donne des résultats différents... il n'est donc pas très utile d'y passer beaucoup de temps !\n",
    "\n",
    "Ré-estimer le modèle supposé optimal avant de tracer le graphe des résidus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nnet.reg=nnet(O3obs~.,data=datappr,size=3,decay=2,linout=TRUE,maxit=200)\n",
    "# calcul et graphe des résidus\n",
    "fit.nnetr=predict(nnet.reg,data=datappr)\n",
    "res.nnetr=fit.nnetr-datappr[,\"O3obs\"]\n",
    "plot.res(fit.nnetr,res.nnetr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Cas de la discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# apprentissage\n",
    "nnet.dis=nnet(DepSeuil~.,data=datappq,size=5,decay=0) \n",
    "summary(nnet.reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La validation croisée est toujours nécessaire afin de tenter d'optimiser les choix en présence : nombre de neurones, *decay* et éventuellement le nombre max d'itérations. \n",
    "\n",
    "L'initialisation de l'apprentissage d'un réseau de neurone comme celle de l'estimation de l'erreur par validation croisée sont aléatoires. Chaque exécution donne donc des résultats différents. À ce niveau, il serait intéressant de construire un plan d'expérience à deux facteurs (ici, les paramètres de taille et *decay*) de chacun trois niveaux. Plusieurs réalisations pour chaque combinaison des niveaux suivies d'un test classique d'anova permettraient de se faire une idée plus juste de l'influence de ces facteurs sur l'erreur. \n",
    "\n",
    "Noter la taille et le *decay* optimaux et ré-estimer le modèle pour ces valeurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(tune.nnet(DepSeuil~.,data=datappq,size=c(3,4,5),decay=c(0,1,2),maxit=200,linout=FALSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nnet.dis=nnet(DepSeuil~.,data=datappq,size=5,decay=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Prévisions de l'échantillon test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Différentes prévisions sont considérées assorties des erreurs estimées sur l'échantillon test. Prévision quantitative de la concentration, prévision de dépassement à partir de la prévision quantitative et directement la prévision de dépassement à partir de l'arbre de décision. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calcul des prévisions\n",
    "pred.nnetr=predict(nnet.reg,newdata=datestr)\n",
    "pred.nnetq=predict(nnet.dis,newdata=datestq) \n",
    "# Erreur quadratique moyenne de prévision\n",
    "sum((pred.nnetr-datestr[,\"O3obs\"])^2)/nrow(datestr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Matrice de confusion pour la prévision du \n",
    "# dépassement de seuil (régression)\n",
    "table(pred.nnetr>150,datestr[,\"O3obs\"]>150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Même chose pour la discrimination\n",
    "table(pred.nnetq>0.5,datestq[,\"DepSeuil\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5 Courbes ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rocnnetr=pred.nnetr/300\n",
    "prednnetr=prediction(rocnnetr,datestq$DepSeuil)\n",
    "perfnnetr=performance(prednnetr,\"tpr\",\"fpr\")\n",
    "rocnnetq=pred.nnetq\n",
    "prednnetq=prediction(rocnnetq,datestq$DepSeuil)\n",
    "perfnnetq=performance(prednnetq,\"tpr\",\"fpr\")\n",
    "# tracer les courbes ROC en les superposant pour mieux comparer\n",
    "plot(perflogit,col=1)\n",
    "plot(perfnnetr,col=2,add=TRUE) \n",
    "plot(perfnnetq,col=3,add=TRUE)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Agrégation de modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les sections précédentes ont permis d'expérimenter les constructions d'un modèle de prévision assorties du problème récurrent lié à l'optimisation de la complexité d'un modèle. Cette section aborde d'autres stratégies dont l'objectif est de s'affranchir de ce problème de choix, par des méthodes se montrant pas ou très peu sensibles au sur-apprentissage ; c'est le cas des algorithmes d'agrégation de modèles.\n",
    "\n",
    "Cette section propose de mettre en évidence la plus ou moins grande influence des paramètres de ces méthodes. \n",
    "* *Random forest*: nombre d'arbres et nombre de variables tirées (*mtry*) aléatoirement et intérêt des critères de Breiman permettant de mesurer l'influence des variables au sein d'une famille agrégée de modèles. \n",
    "* Le *bagging*, cas particulier de forêt aléatoire, n'est pas traité;\n",
    "* *Boosting*: profondeur d'arbre, nombre d'itérations ou d'arbres et coefficient de *shrinkage*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Forêts aléatoires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le programme est disponible dans la librairie *randomForest*. Il est écrit en fortran, donc en principe efficace en terme de rapidité d'exécution, et facile à utiliser grâce à une interface avec R. La comparaison avec Python montre qu'il n'est finalement pas très efficace sans doute à cause de l'interface avec R. Les paramètres et sorties sont explicités dans l'aide en ligne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Régression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(randomForest)\n",
    "rf.reg=randomForest(O3obs~., data=datappr,xtest=datestr[,-2],ytest=datestr[,\"O3obs\"],\n",
    "   ntree=500,do.trace=50,importance=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relancer en faisant varier les paramètres mtry et ntree pour voir leur peu d'influence sur les erreurs.\n",
    "\n",
    "Calcul et graphe des résidus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fit.rfr=rf.reg$predicted\n",
    "res.rfr=fit.rfr-datappr[,\"O3obs\"]\n",
    "plot.res(fit.rfr,res.rfr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf.dis=randomForest(DepSeuil~.,data=datappq,xtest=datestq[,-10],ytest=datestq[,\n",
    "   \"DepSeuil\"],ntree=500,do.trace=50,importance=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commenter les erreurs, tester d'autres exécutions avec d'autres valeurs des paramètres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prévision de l'échantillon test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred.rfr=rf.reg$test$predicted\n",
    "pred.rfq=rf.dis$test$predicted\n",
    "# Erreur quadratique moyenne de prévision\n",
    "sum((pred.rfr-datestr[,\"O3obs\"])^2)/nrow(datestr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Matrice de confusion pour la prévision du \n",
    "# dépassement de seuil (régression)\n",
    "table(pred.rfr>150,datestr[,\"O3obs\"]>150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Même chose pour la discrimination\n",
    "table(pred.rfq,datestq[,\"DepSeuil\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importance des variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle obtenu est ininterprétable mais des coefficients estiment les contributions des variables dans leur participation à la discrimination. Comparer avec les variables sélectionnées par les autres modèles. deux critères d'importance sont proposés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sort(round(importance(rf.reg), 2)[,1], decreasing=TRUE)\n",
    "sort(round(importance(rf.dis), 2)[,4], decreasing=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deux librairies proposent des versions relativement  sophistiquées des algorithmes de *boosting* dans R. La librairie *boost* propose 4 approches : *adaboost, bagboost* et deux *logitboost*. Développées pour une problématique particulière : l'analyse des données d'expression génomique, elle n'est peut-être pas complètement adaptée aux données étudiées ; elles se limitent à des prédicteurs quantitatifs et peut fournir des résultats étranges. La librairie *gbm* lui est préférée ; elle offre aussi plusieurs versions dépendant de la fonction coût choisie. Une librairie plus récente *xgboost* intègre des fonctionnalités de parallélisation. Elle serait également à tester.\n",
    "\n",
    "La variable à prévoir doit être codée numériquement (0,1) pour cette implémentation. Le nombre d'itérations, ou nombre d'arbres, est paramétré ainsi qu'un coefficient de rétrécissement (*shrinkage*) contrôlant le taux ou pas d'apprentissage. Attention, par défaut, ce paramètre a une valeur très faible (0.001) et il faut un nombre important d'itérations (d'arbres) pour atteindre une estimation raisonnable. La qualité est visualisée par un graphe représentant l'évolution de l'erreur d'apprentissage. D'autre part, une procédure de validation croisée est incorporée afin d'optimiser le nombre d'arbres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Régression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(gbm)\n",
    "boost.reg=gbm(O3obs~., data=datappr,distribution=\"gaussian\",n.trees=500, cv.folds=10,\n",
    "        n.minobsinnode = 5,shrinkage=0.03,verbose=FALSE)\n",
    "# fixer verbose à FALSE pour éviter trop de sorties\n",
    "plot(boost.reg$cv.error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# nombre optimal d'itérations par valiation croisée\n",
    "best.iter=gbm.perf(boost.reg,method=\"cv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut s'assurer de l'absence d'un phénomène de sur-apprentissage critique en calculant puis traçant l'évolution de l'erreur sur l'échantillon test en fonction du nombre d'arbre dans le modèle. L'erreur reste stable autour du nombre d'arbres sélectionné et matérialisé par la ligne verticale. Tester ces fonctions en faisant varier le coefficient de rétrécissement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test=numeric()\n",
    "for (i in 10:500){\n",
    "pred.test=predict(boost.reg,newdata=datestr,n.trees=i)\n",
    "err=sum((pred.test-datestr[,\"O3obs\"])^2)/nrow(datestr)\n",
    "test=c(test,err)}\n",
    "plot(10:500,test,type=\"l\")\n",
    "abline(v=best.iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discrimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention, la variable à modéliser doit être codée $(0, 1)$ et il faut préciser un autre paramètre de distribution pour considérer le bon terme d'erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datappq2=datappq\n",
    "datappq2[,\"DepSeuil\"]=as.numeric(datappq[,\"DepSeuil\"])-1\n",
    "boost.dis=gbm(DepSeuil~.,data=datappq2,distribution=\"adaboost\",n.trees=500, cv.folds=10,\n",
    "              n.minobsinnode = 5,shrinkage=0.03,verbose=FALSE)\n",
    "plot(boost.dis$cv.error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# nombre optimal d'itérations \n",
    "best.ited=gbm.perf(boost.dis,method=\"cv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme pour la régression, il est possible de faire varier le coefficient de rétrécissement en l'associant au nombre d'arbres dans le modèle.\n",
    "\n",
    "Calcul des résidus et graphe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fit.boostr=boost.reg$fit\n",
    "res.boostr=fit.boostr-datappr[,\"O3obs\"]\n",
    "plot.res(fit.boostr,res.boostr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4 Echantillon test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred.boostr=predict(boost.reg,newdata=datestr,n.trees=best.iter)\n",
    "# Erreur quadratique moyenne de prévision\n",
    "sum((pred.boostr-datestr[,\"O3obs\"])^2)/nrow(datestr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Matrice de confusion pour la prévision \n",
    "# du dépassement de seuil (régression)\n",
    "table(pred.boostr>150,datestr[,\"O3obs\"]>150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Même chose pour la discrimination\n",
    "pred.boostd=predict(boost.dis,newdata=datestq,n.trees=best.ited)\n",
    "table(as.factor(sign(pred.boostd)),datestq[,\"DepSeuil\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelle  stratégie d'agrégation de modèles vous semble fournir le meilleur résultat de prévision ? Est-elle, sur ce jeu de données, plus efficace que les modèles classiques expérimentés auparavant ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5 Courbes ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rocrfr=pred.rfr/300\n",
    "predrfr=prediction(rocrfr,datestq$DepSeuil)\n",
    "perfrfr=performance(predrfr,\"tpr\",\"fpr\")\n",
    "\n",
    "rocbstr=pred.boostr/300\n",
    "predbstr=prediction(rocbstr,datestq$DepSeuil)\n",
    "perfbstr=performance(predbstr,\"tpr\",\"fpr\")\n",
    "# tracer les courbes ROC en les superposant \n",
    "# pour mieux comparer\n",
    "plot(perflogit,col=1)\n",
    "plot(perfrfr,col=2,add=TRUE)  \n",
    "plot(perfbstr,col=3,add=TRUE)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 10 Séparateur à Vaste Marge (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Malgré les assurances théoriques concernant ce type d'algorithme, les résultats dépendant fortement du choix des paramètres. Nous nous limiterons d'abord au noyau gaussien (choix par défaut) ; la fonction *tune.svm* permet de tester facilement plusieurs situations en estimant la qualité de prévision par validation croisée sur une grille. Le temps d'exécution en R est un peu long... en effet, contrairement à beaucoup d'algorithmes de modélisation, la complexité de l'algorithme de résolution des SVM croît très sensiblement avec le nombre d'observations mais moins avec le nombre de variables. Cette remarque est importante quant à l'adéquation à trouver entre données et méthode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 10.2 Régression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien qu'initialement développés dans le cas d'une variable binaire, les SVM ont été étendus aux problèmes de régression. L'estimation et l'optimisation du coefficient de pénalisation sont obtenues par les commandes suivantes.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm.reg=svm(O3obs~.,data=datappr)\n",
    "plot(tune.svm(O3obs~.,data=datappr,cost=c(1, 1.5,2,2.5,3,3.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Par défaut la pénalisation (cost) vaut 1. Noter la pénalisation optimale pour le noyau considéré (gaussien). Ré-estimer le modèle supposé optimal avant de tracer le graphe des résidus. Comme précédemment, observer que plusieurs exécutions conduisent à des résultats différents et donc que l'optimisaiton de ce paramètre est pour le moins délicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm.reg=svm(O3obs~.,data=datappr,cost=2)\n",
    "# calcul et graphe des résidus\n",
    "fit.svmr=predict(svm.reg,data=datappr)\n",
    "res.svmr=fit.svmr-datappr[,\"O3obs\"]\n",
    "plot.res(fit.svmr,res.svmr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observer l'effet ''couloir'' sur les résidus. Ceci est une conséquence de la fonction d'erreur robuste utilisée pour  l'estimation des svm en régression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 Discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# optimisation\n",
    "plot(tune.svm(DepSeuil~.,data=datappq,cost=c(1,1.25,1.5,1.75,2))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apprentissage\n",
    "svm.dis=svm(DepSeuil~.,data=datappq,cost=1.25) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4 Echantillon test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred.svmr=predict(svm.reg,newdata=datestr)\n",
    "pred.svmq=predict(svm.dis,newdata=datestq)\n",
    "# Erreur quadratique moyenne de prévision\n",
    "sum((pred.svmr-datestr[,\"O3obs\"])^2)/nrow(datestr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Matrice de confusion pour la prévision du dépassement de seuil (régression)\n",
    "table(pred.svmr>150,datestr[,\"O3obs\"]>150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Même chose pour la discrimination\n",
    "table(pred.svmq,datestq[,\"DepSeuil\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.5 Courbes ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rocsvmr=pred.svmr/300\n",
    "predsvmr=prediction(rocsvmr,datestq$DepSeuil)\n",
    "perfsvmr=performance(predsvmr,\"tpr\",\"fpr\")\n",
    "# re-estimer le modèle pour obtenir des \n",
    "# probabilités  de classe plutôt que des classes\n",
    "svm.dis=svm(DepSeuil~.,data=datappq,cost=1.25,\n",
    "  probability=TRUE)\n",
    "pred.svmq=predict(svm.dis,newdata=datestq,\n",
    "  probability=TRUE)\n",
    "rocsvmq=attributes(pred.svmq)$probabilities[,2]\n",
    "predsvmq=prediction(rocsvmq,datestq$DepSeuil)\n",
    "perfsvmq=performance(predsvmq,\"tpr\",\"fpr\")\n",
    "# tracer les courbes ROC en les superposant \n",
    "# pour mieux comparer\n",
    "plot(perflogit,col=1)\n",
    "plot(perfsvmr,col=2,add=TRUE) \n",
    "plot(perfsvmq,col=3,add=TRUE)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthèse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif final est d'arriver à une comparaison fine et synthétique des différentes méthodes pour conclure sur les choix: \n",
    "* Quelle méthode utiliser pour prévoir au mieux la concentration d'ozone ?\n",
    "* Quelle stratégie et quelle méthode utiliser pour prévoir le dépassement du seuil : \n",
    "\t- Prévision quantitative puis comparaison au seuil ?\n",
    "\t- Prévision qualitative ?\n",
    "La taille de l'échantillon test, autour de 200 jours, est relativement modeste pour espérer une bonne précision sur la foi d'un seul échantillon. Pour préciser la comparaison, c'est-à-dire pour prendre en compte la variance de l'estimation de l'erreur, le processus de séparation de l'échantillon en apprentissage et test  est itéré B fois.\n",
    "\n",
    "Souci: mal parallélisée ou plutôt pas parallélisée, cette opération est à exécuter en batch car elle nécessite plusieurs heures de calcul. Ce sont les limites de R! La version en python est beaucoup plus efficace.\n",
    "\n",
    "Le [programme](http://www.math.univ-toulouse.fr/~besse/Wikistat/programmes/comparaison_ozone.R) n'est pas optimisé mais accessible. Il conduit aux résultats ci-dessous avec 30 itérations. Quelle conclusion en tirer sur le choix de la stratégie, celle de la méhode ?\n",
    "\n",
    "Taux d’erreur moyens à partir des prévisions de régression : \n",
    "\n",
    "Acova | tree.r | Res.neur.r |  Bagging.r | foret.alea.r | Boost.gbm.r |  SVM.r \n",
    ":----:|:------:|:----------:|:----------:|:------------:|:-----------:|:------:\n",
    "12%   | 14%    |  13%       |    14%     |     11%      |     13%     |   12%  \n",
    "\n",
    "Taux d’erreur moyens à partir des prévisions de discrimination : \n",
    "\n",
    "Reg.log | Ann.disc | tree.q  |  Res.neur.q |  Bagging.q | foret.alea.q | Boost.gbm.q |  SVM \n",
    ":------:|:--------:|:-------:|:----------:|:------------:|:-----------:|:-----------:|-------\n",
    "  12%   |   12%    |  14%    |    14%     |     12%      |     11%     |   12%       |   12%\n",
    "  \n",
    "<img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/programmes/ozone-compq-boites.jpg\"  height=\"60\" alt=\"boxes\"/>\n",
    "<center>*Figure 1: Comparaison des distributions des erreurs de prévision*</center>\n",
    "\n",
    "<img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/programmes/ozone-comp-roc.jpg\"  height=\"80\" alt=\"ROC\"/>\n",
    "<center>*Figure 2: Comparaison des courbes ROC*</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
